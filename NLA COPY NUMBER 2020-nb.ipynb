{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T11:01:19.700493Z",
     "start_time": "2020-02-13T11:01:17.976163Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import more_itertools\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import pysam\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.colors\n",
    "import sklearn.cluster\n",
    "from scipy.cluster.hierarchy import leaves_list\n",
    "from scipy.stats import linregress\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from singlecellmultiomics.utils import createRowColorDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T11:01:19.709361Z",
     "start_time": "2020-02-13T11:01:19.701861Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define chromsome order:\n",
    "def sort_chromosome_names(l):\n",
    "    chrom_values = []\n",
    "    for chrom in l:\n",
    "        chrom_value = None\n",
    "        chrom = chrom.replace('chr','')\n",
    "        if chrom == 'X':\n",
    "            chrom_value = 99\n",
    "        elif chrom == 'M':\n",
    "            chrom_value = 101\n",
    "        elif chrom == 'EBV':\n",
    "            chrom_value = 102\n",
    "        else:\n",
    "            chrom_value = int(chrom)\n",
    "        chrom_values.append(chrom_value)\n",
    "    \n",
    "    indices = sorted(range(len(chrom_values)),key=lambda x:chrom_values[x])\n",
    "    return [l[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T11:01:19.713599Z",
     "start_time": "2020-02-13T11:01:19.711537Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_size = 500000\n",
    "MAXCP = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T11:01:23.379333Z",
     "start_time": "2020-02-13T11:01:21.536944Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat( \n",
    "    (\n",
    "    pd.read_pickle(plate) \n",
    "    for plate in list(glob(f'/home/buysdb/repos/ColonOrganoidDynamics/data/APKS*-P*/tagged.bam.table.bs_{bin_size}.CNV_reads.pickle.gz'))\n",
    "    ),\n",
    "    sort=True,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T11:01:25.236317Z",
     "start_time": "2020-02-13T11:01:25.185951Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop([ b for b in df.columns if b[1] in ['chrY','chrM','chrEBV'] or 'decoy' in b[1] or 'chrUn' in b[1] or b[1].endswith('_alt')  or b[1].endswith('_random')],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T11:01:27.996363Z",
     "start_time": "2020-02-13T11:01:27.991531Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loghist(x, bins):\n",
    "    hist, bins = np.histogram(x, bins=bins)\n",
    "    logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
    "    plt.hist(x, bins=logbins)\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = df.sum(level=[1,2], axis=1).median(1)\n",
    "total=df.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(med, total)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.scatter(med,total)\n",
    "x=np.linspace(0,max(med),4)\n",
    "plt.plot(x, intercept + slope*x, 'r', label='fitted line')\n",
    "plt.xlabel('median reads')\n",
    "plt.ylabel('total reads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine mappability per bin:\n",
    "df_wo_alleles = df.sum(level=[1,2], axis=1)\n",
    "bin_names = set(df_wo_alleles.columns)\n",
    "import collections\n",
    "bininfo = collections.defaultdict(collections.Counter) # bin\n",
    "with open('/media/buysdb/eightA/references/hg38/simulated_CATG_single_69.mapability.stats.tsv') as f:\n",
    "    for line in f:\n",
    "        if len(line.strip())==0:\n",
    "            continue\n",
    "        chrom, pos, strand, correct, lost, gained = line.strip().split()\n",
    "        bin_idx = int(int(pos)/bin_size)\n",
    "        if not (chrom, bin_idx) in bin_names:\n",
    "            continue\n",
    "        \n",
    "        bininfo[(chrom, bin_idx)]['lost'] += int(lost)\n",
    "        bininfo[(chrom, bin_idx)]['gained'] += int(gained)\n",
    "        bininfo[(chrom, bin_idx)]['correct'] += int(correct)\n",
    "        \n",
    "bininfo = pd.DataFrame(bininfo).fillna(0).T\n",
    "plt.scatter( bininfo['lost'], bininfo['correct'],s=2,alpha=0.2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select bins with proper mappability\n",
    "sbins = bininfo[(bininfo['correct']>3000)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sum allele data for all columns: (creates a non-allele specific matrix)\n",
    "\n",
    "total = df_wo_alleles.sum(1)\n",
    "\n",
    "df_wo_alleles_pre_normed = (df_wo_alleles[sbins]/bininfo['correct'][sbins])*bininfo['correct'][sbins].mean()\n",
    "\n",
    "df_wo_alleles_normed = ((df_wo_alleles_pre_normed.T.fillna(0) / df_wo_alleles_pre_normed[sbins].T.mean().fillna(0)).T) * 2\n",
    "\n",
    "df_wo_alleles_normed=df_wo_alleles_normed[df_wo_alleles_pre_normed.median(1)>0]\n",
    "\n",
    "df_wo_alleles_normed.loc[:,'total'] = total\n",
    "fig, ax = plt.subplots(figsize=(10,100))\n",
    "\n",
    "sns.heatmap(df_wo_alleles_normed.sort_index(1).sort_values('total')['chr9'],ax=ax,vmax=4)\n",
    "df_wo_alleles_normed=df_wo_alleles_normed.drop('total',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:19:14.815932Z",
     "start_time": "2020-02-12T12:19:14.717298Z"
    }
   },
   "outputs": [],
   "source": [
    "#reference = pysam.FastaFile('/media/sf_data/references/GATK-Bundle/hg38/Homo_sapiens_assembly38.fasta')\n",
    "reference = pysam.FastaFile('/media/buysdb/eightA/references/hg38/Homo_sapiens_assembly38.fasta')\n",
    "chrom_sizes= dict( zip(reference.references, reference.lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:20:50.076614Z",
     "start_time": "2020-02-12T12:19:14.954714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract GC percentage from reference for the selected bin size:\n",
    "bins_to_gc = {}\n",
    "\n",
    "for contig,bin_index in df_wo_alleles_normed.columns:\n",
    "    \n",
    "    if not (contig,bin_index) in bins_to_gc:\n",
    "        sequence = reference.fetch(contig, bin_index*bin_size, (1+bin_index)*bin_size ).upper()\n",
    "        gc = sequence.count('G')+sequence.count('C')\n",
    "        gcrat = (gc) / ((sequence.count('A')+sequence.count('T')+gc))\n",
    "        bins_to_gc[ (contig,bin_index) ] = gcrat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:20:50.224166Z",
     "start_time": "2020-02-12T12:20:50.078035Z"
    }
   },
   "outputs": [],
   "source": [
    "gc_matched = df_wo_alleles_normed.T.join( pd.DataFrame({'gc':bins_to_gc}), how='left')['gc']\n",
    "gc_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:20:52.828669Z",
     "start_time": "2020-02-12T12:20:50.232219Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is the global GC bias:\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter( gc_matched, df_wo_alleles_normed.mean() )\n",
    "correction = lowess(df_wo_alleles_normed.mean(), gc_matched)\n",
    "plt.plot(correction[:,0], correction[:,1], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_correct(args):\n",
    "    observations, gc_vector,MAXCP = args\n",
    "    correction = lowess(observations, gc_vector)\n",
    "    return np.clip(observations / np.interp( gc_vector, correction[:,0], correction[:,1] ) , 0,MAXCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "workers = Pool(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_bins=df_wo_alleles_normed.columns\n",
    "gc_vector = gc_matched[keep_bins]\n",
    "\n",
    "corrected_cells = list( workers.imap(\n",
    "    gc_correct, [(row,gc_vector,MAXCP) for cell,row in df_wo_alleles_normed[keep_bins].iterrows()] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_order = sort_chromosome_names(list(set([chrom for chrom,_ in corrected_cells[0].index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumlen = {}\n",
    "prev= 0\n",
    "for chrom in chrom_order:\n",
    "    cumlen[chrom]=prev\n",
    "    prev+=chrom_sizes[chrom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_cells = pd.concat(corrected_cells,axis=1).T.sort_index(1)[chrom_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap( corrected_cells.iloc[:600,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:20:52.963685Z",
     "start_time": "2020-02-12T12:20:52.883498Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.hist( df[('allele1','chr18')].sum(1) / ( df[('allele2','chr18')].sum(1) + df[('allele1','chr18')].sum(1) ), bins=50 )\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_alleles_gc_corr = corrected_cells*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_bounds =  {\n",
    "            'chr1': { 15, 155, 157, 201, 436},\n",
    "             'chr2': {0, 135, 467},\n",
    "             'chr3': {0, 252, 387},\n",
    "             'chr4': {0, 372},\n",
    "             'chr5': {0, 348},\n",
    "             'chr6': {0, 55, 66, 68, 333},\n",
    "             'chr7': {0, 302},\n",
    "             'chr8': {0, 5, 8, 82, 123, 279},\n",
    "             'chr9': {0, 7, 8, 69, 76, 216},\n",
    "             'chr10': {0, 91, 255},\n",
    "             'chr11': {0, 256},\n",
    "             'chr12': {0, 142, 181, 258},\n",
    "             'chr13': {0, 190},\n",
    "             'chr14': {0, 173},\n",
    "             'chr15': {0, 10, 16, 153},\n",
    "             'chr16': {0, 150},\n",
    "             'chr17': {0, 97, 152},\n",
    "             'chr18': {0, 29, 32, 37, 42, 147},\n",
    "             'chr19': {0, 107},\n",
    "             'chr20': {0, 116},\n",
    "             'chr21': {0, 63},\n",
    "             'chr22': {0, 64},\n",
    "             'chrX': {0, 292}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list( more_itertools.windowed(sorted(list(segment_bounds['chr1'])),2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom, bounds in segment_bounds.items():\n",
    "    for region in more_itertools.windowed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcalls = pd.read_pickle('../../Analysis (another copy)/cnv_normaliser/figures/resources/hybrid_cn_matrix_reduced_segments_variance.pickle.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for bin_chrom, bin_start in selected_data.index:\n",
    "    if bin_chrom!=chrom:\n",
    "        continue\n",
    "        \n",
    "    print(bin_start*bin_size, bin_chrom==chrom, bin_start*bin_size*1000>=start, (bin_start*(1000*bin_size+1))<=end )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = df_wo_alleles_gc_corr[chrom_order].loc[cell,:]\n",
    "for chrom, allele, (start, end) in finalcalls.columns:\n",
    "    start = start/bin_size\n",
    "    end = end/bin_size\n",
    "    bins = [\n",
    "        (bin_chrom==chrom and bin_start*bin_size>=start and (bin_start*(bin_size+1))<=end  ) for bin_chrom, bin_start in selected_data.index\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df_wo_alleles_gc_corr['chr1'].diff(periods=1,axis=1).var(1)\n",
    "plt.hist( var, bins=100)\n",
    "\n",
    "var_threshold=0.6\n",
    "\n",
    "plt.show()\n",
    "df_wo_alleles_gc_corr.loc[:,'var'] =  var\n",
    "df_wo_alleles_gc_corr = df_wo_alleles_gc_corr.sort_values('var').drop('var',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_cells = 40\n",
    "\n",
    "ht = 2.5\n",
    "lt = 1.5\n",
    "\n",
    "fig, axes = plt.subplots(show_cells,1,figsize=(12,1*show_cells), sharex=True, sharey=True)\n",
    "sns.despine()\n",
    "for i,ax,cell in zip(range(show_cells), axes, [idx for idx in df_wo_alleles_gc_corr.index if idx in finalcalls.index]):\n",
    "    \n",
    "    \n",
    "    inc = df_wo_alleles_gc_corr[chrom_order].loc[cell,:]>ht\n",
    "    inc[~inc]=np.nan\n",
    "    (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]*inc).plot(style='.',ms=0.5,ax=ax,color=tuple(np.array((131,40,30))/255))\n",
    "    \n",
    "    inc = df_wo_alleles_gc_corr[chrom_order].loc[cell,:]<lt\n",
    "    inc[~inc]=np.nan\n",
    "    (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]*inc).plot(style='.',ms=0.5,ax=ax,color=tuple(np.array((94,86,157,255))/255))\n",
    "    \n",
    "    inc = (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]>=lt) & (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]<=ht)\n",
    "    inc[~inc]=np.nan\n",
    "    (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]*inc).plot(style='.',ms=1,ax=ax,color='grey', alpha=0.5)\n",
    "\n",
    "    \n",
    "    ax.set_ylim(-1,5)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if False:\n",
    "        selected_data = df_wo_alleles_gc_corr[chrom_order].loc[cell,:]\n",
    "        for k in finalcalls.columns:\n",
    "            chrom, allele, (start, end) = k\n",
    "            if allele != 'none':\n",
    "                continue\n",
    "            start = start/bin_size\n",
    "            end = end/bin_size\n",
    "            bins = [\n",
    "                1 if (bin_chrom==chrom and bin_start*bin_size>=start and (bin_start*(bin_size+1))<=end  ) else np.nan for bin_chrom, bin_start in selected_data.index\n",
    "            ]\n",
    "\n",
    "            call = finalcalls.loc[cell][k]\n",
    "            if call>2:\n",
    "                (selected_data * bins).plot(style='.',ms=1,ax=ax,color=(131,40,30))\n",
    "            elif call==1:\n",
    "                (selected_data * bins).plot(style='.',ms=1,ax=ax,color=(94,86,157))\n",
    "\n",
    "\n",
    "    \n",
    "    prev=None\n",
    "    for binidx, (chrom, binpos) in enumerate(df_wo_alleles_gc_corr[chrom_order].columns):\n",
    "        if prev is not None and chrom!=prev:\n",
    "            ax.axvline(binidx-1,c='k',lw=1, )\n",
    "        prev = chrom\n",
    "    ax.set_yticks([0,2,4])\n",
    "    #ax.set_ylabel('Copy number')\n",
    "plt.savefig('raw_copy_numbers.svg')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir single_cell_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cells = 40\n",
    "\n",
    "\n",
    "ht = 2.5\n",
    "lt = 1.5\n",
    "\n",
    "\n",
    "for i,cell in zip(range(show_cells), [idx for idx in df_wo_alleles_gc_corr.index if idx in finalcalls.index]):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(12,1.5))\n",
    "    sns.despine()\n",
    "    \n",
    "    inc = df_wo_alleles_gc_corr[chrom_order].loc[cell,:]>ht\n",
    "    inc[~inc]=np.nan\n",
    "    (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]*inc).plot(style='.',ms=0.5,ax=ax,color=tuple(np.array((131,40,30))/255))\n",
    "    \n",
    "    inc = df_wo_alleles_gc_corr[chrom_order].loc[cell,:]<lt\n",
    "    inc[~inc]=np.nan\n",
    "    (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]*inc).plot(style='.',ms=0.5,ax=ax,color=tuple(np.array((94,86,157,255))/255))\n",
    "    \n",
    "    inc = (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]>=lt) & (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]<=ht)\n",
    "    inc[~inc]=np.nan\n",
    "    (df_wo_alleles_gc_corr[chrom_order].loc[cell,:]*inc).plot(style='.',ms=1,ax=ax,color='grey', alpha=0.5)\n",
    "\n",
    "    \n",
    "    ax.set_ylim(-1,5)\n",
    "    \n",
    "\n",
    "    \n",
    "  \n",
    "    prev=None\n",
    "    for binidx, (chrom, binpos) in enumerate(df_wo_alleles_gc_corr[chrom_order].columns):\n",
    "        if prev is not None and chrom!=prev:\n",
    "            ax.axvline(binidx-1,c='k',lw=1, )\n",
    "        prev = chrom\n",
    "    ax.set_yticks([0,2,4])\n",
    "    #ax.set_ylabel('Copy number')\n",
    "    plt.savefig(f'./single_cell_traces/{cell}.svg')\n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:23:40.545420Z",
     "start_time": "2020-02-12T12:23:39.716056Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_cells = 40\n",
    "\n",
    "fig, axes = plt.subplots(10,1,figsize=(12,10), sharex=True, sharey=True)\n",
    "for i,ax in zip(range(10), axes):\n",
    "    \n",
    "    for chrom in chrom_order:\n",
    "\n",
    "        #df_wo_alleles_gc_corr[chrom].iloc[i,:].plot(style='.',ms=1,ax=ax,color='grey')\n",
    "        ax.set_ylim(-1,5)\n",
    "        \n",
    "        x_coords = df_wo_alleles_gc_corr[chrom].iloc[i,:].index.values*bin_size + cumlen[chrom]\n",
    "        ax.scatter(x_coords,df_wo_alleles_gc_corr[chrom].iloc[i,:].values, marker='.',s=1 )\n",
    "        \n",
    "        prev=None\n",
    "        for binidx, (chrom, binpos) in enumerate(df_wo_alleles_gc_corr[chrom_order].columns):\n",
    "            if prev is not None and chrom!=prev:\n",
    "                ax.axvline(binidx-1,c='k',lw=1, )\n",
    "            prev = chrom\n",
    "        ax.set_yticks([0,2,4])\n",
    "        #ax.set_ylabel('Copy number')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum allele data for all columns: (creates a non-allele specific matrix)\n",
    "\n",
    "total = df_wo_alleles.sum(1)\n",
    "\n",
    "df_wo_alleles_pre_normed = (df_wo_alleles[sbins]/bininfo['correct'][sbins])*bininfo['correct'][sbins].mean()\n",
    "\n",
    "df_wo_alleles_normed = ((df_wo_alleles_pre_normed.T.fillna(0) / df_wo_alleles_pre_normed[sbins].T.mean().fillna(0)).T) * 2\n",
    "\n",
    "df_wo_alleles_normed=df_wo_alleles_normed[df_wo_alleles_pre_normed.median(1)>0]\n",
    "\n",
    "df_wo_alleles_normed.loc[:,'total'] = total\n",
    "fig, ax = plt.subplots(figsize=(10,100))\n",
    "\n",
    "sns.heatmap(df_wo_alleles_normed.sort_index(1).sort_values('total')['chr9'],ax=ax,vmax=4)\n",
    "df_wo_alleles_normed=df_wo_alleles_normed.drop('total',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(var,df_wo_alleles.sum(1)[df_wo_alleles_pre_normed.median(1)>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_wo_alleles.sum(1)[df_wo_alleles_pre_normed.median(1)>0].to_frame()\n",
    "s.columns=['uniquely mapping reads']\n",
    "v = var.to_frame()\n",
    "v.columns=['variance of derivative']\n",
    "s = v.join(s)\n",
    "\n",
    "\n",
    "s.plot.scatter('uniquely mapping reads','variance of derivative',s=2,c='grey', alpha=0.2)\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.scatter(s.loc[segmented_matrix.index]['uniquely mapping reads'],\n",
    "            s.loc[segmented_matrix.index]['variance of derivative'],\n",
    "                                           marker='x',s=0.05,c='g')\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[segmented_matrix.index].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Some cells are a bit or very noisy, calculate noise for chromosome 1\n",
    "var = df_wo_alleles_gc_corr['chr1'].diff(periods=1,axis=1).var(1)\n",
    "plt.hist( var, bins=100)\n",
    "\n",
    "var_threshold=0.6\n",
    "\n",
    "plt.show()\n",
    "df_wo_alleles_gc_corr.loc[:,'var'] =  var\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(10,1,figsize=(10,10), sharex=True, sharey=True)\n",
    "d = df_wo_alleles_gc_corr[df_wo_alleles_gc_corr['var']<=var_threshold].sort_values('var').drop('var',1)['chr9'].iloc[:10,:]\n",
    "for i,ax in zip(range(10), axes):\n",
    "    d.iloc[i,:].plot(style='.',ms=1,ax=ax)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(10,1,figsize=(10,10), sharex=True, sharey=True)\n",
    "d = df_wo_alleles_gc_corr[df_wo_alleles_gc_corr['var']<=var_threshold].sort_values('var').drop('var',1)['chr9'].iloc[-10:,:]\n",
    "for i,ax in zip(range(10), axes):\n",
    "    d.iloc[i,:].plot(style='.',ms=1,ax=ax)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,100))\n",
    "sns.heatmap(df_wo_alleles_gc_corr.sort_index(1).sort_values('var')['chr9'],ax=ax,vmax=4)\n",
    "\n",
    "\n",
    "best_cells  = df_wo_alleles_gc_corr[df_wo_alleles_gc_corr['var']<=var_threshold].index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,100))\n",
    "sns.heatmap(df_wo_alleles_gc_corr.loc[best_cells].sort_index(1).sort_values('var')['chr9'],ax=ax,vmax=4)\n",
    "\n",
    "\n",
    "print(f\"{len(best_cells)} cells left\")\n",
    "\n",
    "df_wo_alleles_gc_corr.drop('var',1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform median 2 normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:26:39.587467Z",
     "start_time": "2020-02-12T12:24:44.213502Z"
    }
   },
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "tsne_X = tsne.fit_transform( df_wo_alleles_gc_corr.loc[best_cells] )\n",
    "tsne_X_before_select = tsne.fit_transform( np.clip(df_wo_alleles_gc_corr.fillna(0), 0,MAXCP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:26:39.753930Z",
     "start_time": "2020-02-12T12:26:39.589104Z"
    }
   },
   "outputs": [],
   "source": [
    "k = sklearn.cluster.KMeans(n_clusters=12)\n",
    "clusters = k.fit_predict(tsne_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:26:39.816405Z",
     "start_time": "2020-02-12T12:26:39.757861Z"
    }
   },
   "outputs": [],
   "source": [
    "pargs = {'s':8, 'cmap':plt.get_cmap('tab20')}\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].scatter( tsne_X_before_select[:,0], tsne_X_before_select[:,1])\n",
    "axes[0].set_title('T-SNE of CNV data\\n without GC correction')\n",
    "\n",
    "axes[1].scatter( tsne_X[:,0], tsne_X[:,1],  c=clusters,**pargs)\n",
    "axes[1].set_title('T-SNE of CNV data \\nlow variance filter')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:26:40.602918Z",
     "start_time": "2020-02-12T12:26:39.817971Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "df_norm_gauss = gaussian_filter(df_wo_alleles_gc_corr, (0.01,5))\n",
    "df_norm_gauss = pd.DataFrame(df_norm_gauss, index=df_wo_alleles_gc_corr.index, columns=df_wo_alleles_gc_corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:29:57.181369Z",
     "start_time": "2020-02-12T12:29:19.932390Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster in set(clusters):\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(df_wo_alleles_gc_corr.loc[best_cells,:][clusters==cluster], vmax=MAXCP )\n",
    "    #df_norm_gauss= df_norm_gauss.drop('cluster',1)\n",
    "    plt.title(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:30:24.475572Z",
     "start_time": "2020-02-12T12:30:24.471077Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_cluster= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(oob_score=True,random_state=42)\n",
    "y = clusters==noise_cluster\n",
    "\n",
    "rf.fit(df_wo_alleles_gc_corr.loc[best_cells],y)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise_predictions = rf.predict_proba(df_wo_alleles_gc_corr)[:,0]\n",
    "df_wo_alleles_gc_corr.loc[:,'p']= noise_predictions\n",
    "fig, ax = plt.subplots(figsize=(20,60))\n",
    "#df_wo_alleles_gc_corr['cluster']=clusters\n",
    "sns.heatmap( df_wo_alleles_gc_corr.sort_values('p')['chr18'],ax=ax, vmax=4)\n",
    "df_wo_alleles_gc_corr.drop('p',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99\n",
    "plt.hist(noise_predictions, bins=100)\n",
    "plt.axvline(threshold,c='r')\n",
    "df_wo_alleles_gc_corr[ noise_predictions>=threshold].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:30:27.437361Z",
     "start_time": "2020-02-12T12:30:24.708715Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,80))\n",
    "#df_wo_alleles_gc_corr['cluster']=clusters\n",
    "selected_cells_for_segmentation = (noise_predictions>=threshold)\n",
    "sns.heatmap( df_wo_alleles_gc_corr[selected_cells_for_segmentation], vmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:48:44.071919Z",
     "start_time": "2020-02-12T12:48:11.048816Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap( df_wo_alleles_gc_corr[selected_cells_for_segmentation], \n",
    "               vmax=5, vmin=0, col_cluster= False, method='ward', cmap='bwr',figsize=(20,60))\n",
    "plt.savefig('./binned_200k_clustered_other_corr_reads_rf.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:30:39.039868Z",
     "start_time": "2020-02-12T12:30:38.838609Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sf = df_wo_alleles_gc_corr.loc[best_cells][ clusters==noise_cluster ]\n",
    "high_peaks = scipy.signal.find_peaks( sf.sum() )[0]\n",
    "low_peaks = scipy.signal.find_peaks( -sf.sum() )[0]\n",
    "sf.sum().plot()\n",
    "plt.scatter(high_peaks,sf.sum()[high_peaks], c='r')\n",
    "plt.scatter(low_peaks,sf.sum()[low_peaks], c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:30:44.346849Z",
     "start_time": "2020-02-12T12:30:44.107806Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weight = 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#drate = df_norm.iloc[:,low_peaks].mean(1) # (df_norm.iloc[:,low_peaks].sum(1)*weight).div( (df_norm.iloc[:,low_peaks].sum(1)*weight)+df_norm.iloc[:,high_peaks].sum(1))\n",
    "#drate = (df_norm.iloc[:,low_peaks].sum(1)).div( df_norm.sum(1) )\n",
    "drate = (df_wo_alleles_gc_corr.iloc[:,low_peaks].replace([np.inf, -np.inf], np.nan).fillna(2).mean(1)).div( \n",
    "        (df_wo_alleles_gc_corr.iloc[:,low_peaks].replace([np.inf, -np.inf], np.nan).fillna(2)).mean(1)+\n",
    "        df_wo_alleles_gc_corr.iloc[:,high_peaks].replace([np.inf, -np.inf], np.nan).fillna(2).mean(1))\n",
    "\n",
    "#drate = (drate-drate.mean()).abs()\n",
    "plt.hist( \n",
    "    drate,\n",
    "    bins=150\n",
    ")\n",
    "\n",
    "\n",
    "plt.hist((sf.iloc[:,low_peaks].replace([np.inf, -np.inf], np.nan).fillna(2).mean(1)).div( \n",
    "        (sf.iloc[:,low_peaks].replace([np.inf, -np.inf], np.nan).fillna(2)).mean(1)+\n",
    "        sf.iloc[:,high_peaks].replace([np.inf, -np.inf], np.nan).fillna(2).mean(1)),color='r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T12:48:05.281170Z",
     "start_time": "2020-02-12T12:48:04.667621Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10,1,figsize=(10,10), sharex=True, sharey=True)\n",
    "for i,ax in zip(range(10), axes):\n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation].sort_index(1)[chrom_order].iloc[i,:].plot(style='.',ms=1,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:17:05.643811Z",
     "start_time": "2020-02-12T13:17:05.612474Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger()\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "\n",
    "\n",
    "def cbs_stat(x):\n",
    "    '''Given x, Compute the subinterval x[i0:i1] with the maximal segmentation statistic t. \n",
    "    Returns t, i0, i1'''\n",
    "    \n",
    "    x0 = x - np.mean(x)\n",
    "    n = len(x0)\n",
    "    y = np.cumsum(x0)\n",
    "    e0, e1 = np.argmin(y), np.argmax(y)\n",
    "    i0, i1 = min(e0, e1), max(e0, e1)\n",
    "    s0, s1 = y[i0], y[i1]\n",
    "    return (s1-s0)**2*n/(i1-i0+1)/(n+1-i1+i0), i0, i1+1\n",
    "\n",
    "\n",
    "def tstat(x, i):\n",
    "    '''Return the segmentation statistic t testing if i is a (one-sided)  breakpoint in x'''\n",
    "    n = len(x)\n",
    "    s0 = np.mean(x[:i])\n",
    "    s1 = np.mean(x[i:])\n",
    "    return (n-i)*i/n*(s0-s1)**2\n",
    "\n",
    "def cbs(x, shuffles=1000, p=.05):\n",
    "    '''Given x, find the interval x[i0:i1] with maximal segmentation statistic t. Test that statistic against\n",
    "    given (shuffles) number of random permutations with significance p.  Return True/False, t, i0, i1; True if\n",
    "    interval is significant, false otherwise.'''\n",
    "\n",
    "    max_t, max_start, max_end = cbs_stat(x)\n",
    "    if max_end-max_start == len(x):\n",
    "        return False, max_t, max_start, max_end\n",
    "    if max_start < 5:\n",
    "        max_start = 0\n",
    "    if len(x)-max_end < 5:\n",
    "        max_end = len(x)\n",
    "    thresh_count = 0\n",
    "    alpha = shuffles*p\n",
    "    xt = x.copy()\n",
    "    for i in range(shuffles):\n",
    "        np.random.shuffle(xt)\n",
    "        threshold, s0, e0 = cbs_stat(xt)\n",
    "        if threshold >= max_t:\n",
    "            thresh_count += 1\n",
    "        if thresh_count > alpha:\n",
    "            return False, max_t, max_start, max_end\n",
    "    return True, max_t, max_start, max_end\n",
    "\n",
    "\n",
    "def rsegment(x, start, end, L=[], shuffles=1000, p=.05):\n",
    "    '''Recursively segment the interval x[start:end] returning a list L of pairs (i,j) where each (i,j) is a significant segment.\n",
    "    '''\n",
    "    threshold, t, s, e = cbs(x[start:end], shuffles=shuffles, p=p)\n",
    "    log.info('Proposed partition of {} to {} from {} to {} with t value {} is {}'.format(start, end, start+s, start+e, t, threshold))\n",
    "    if (not threshold) | (e-s < 5) | (e-s == end-start):\n",
    "        L.append((start, end))\n",
    "    else:\n",
    "        if s > 0:\n",
    "            rsegment(x, start, start+s, L)\n",
    "        if e-s > 0:\n",
    "            rsegment(x, start+s, start+e, L)\n",
    "        if start+e < end:\n",
    "            rsegment(x, start+e, end, L)\n",
    "    return L\n",
    "\n",
    "\n",
    "def segment(x, shuffles=1000, p=.05):\n",
    "    '''Segment the array x, using significance test based on shuffles rearrangements and significance level p\n",
    "    '''\n",
    "    start = 0\n",
    "    end = len(x)\n",
    "    L = []\n",
    "    rsegment(x, start, end, L, shuffles=shuffles, p=p)\n",
    "    return L\n",
    "\n",
    "\n",
    "def validate(x, L, shuffles=1000, p=.01):\n",
    "    S = [x[0] for x in L]+[len(x)]\n",
    "    SV = [0]\n",
    "    left = 0\n",
    "    for test, s in enumerate(S[1:-1]):\n",
    "        t = tstat(x[S[left]:S[test+2]], S[test+1]-S[left])\n",
    "        log.info('Testing validity of {} in interval from {} to {} yields statistic {}'.format(S[test+1], S[left], S[test+2], t))\n",
    "        threshold = 0\n",
    "        thresh_count = 0\n",
    "        site = S[test+1]-S[left]\n",
    "        xt = x[S[left]:S[test+2]].copy()\n",
    "        flag = True\n",
    "        for k in range(shuffles):\n",
    "            np.random.shuffle(xt)\n",
    "            threshold = tstat(xt, site)\n",
    "            if threshold > t:\n",
    "                thresh_count += 1\n",
    "            if thresh_count >= p*shuffles:\n",
    "                flag = False\n",
    "                log.info('Breakpoint {} rejected'.format(S[test+1]))\n",
    "                break\n",
    "        if flag:\n",
    "            log.info('Breakpoint {} accepted'.format(S[test+1]))\n",
    "            SV.append(S[test+1])\n",
    "            left += 1\n",
    "    SV.append(S[-1])\n",
    "    return SV\n",
    "\n",
    "\n",
    "def generate_normal_time_series(num, minl=50, maxl=1000):\n",
    "    '''Generate a time series with num segments of minimal length minl and maximal length maxl.  Within a segment,\n",
    "    data is normal with randomly chosen, normally distributed mean between -10 and 10, variance between 0 and 1.\n",
    "    '''\n",
    "    data = np.array([], dtype=np.float64)\n",
    "    partition = np.random.randint(minl, maxl, num)\n",
    "    for p in partition:\n",
    "        mean = np.random.randn()*10\n",
    "        var = np.random.randn()*1\n",
    "        if var < 0:\n",
    "            var = var * -1\n",
    "        tdata = np.random.normal(mean, var, p)\n",
    "        data = np.concatenate((data, tdata))\n",
    "    return data\n",
    "\n",
    "\n",
    "def draw_segmented_data(data, S, title=None, ax=None):\n",
    "    '''Draw a scatterplot of the data with vertical lines at segment boundaries and horizontal lines at means of \n",
    "    the segments. S is a list of segment boundaries.'''\n",
    "    j=sns.scatterplot(range(len(data)),data,color='black',size=.1,legend=None,ax=ax)\n",
    "    for x in S:\n",
    "        j.axvline(x)\n",
    "    for i in range(1,len(S)):\n",
    "        j.hlines(np.mean(data[S[i-1]:S[i]]),S[i-1],S[i],color='green')\n",
    "    j.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#workers.terminate()\n",
    "\n",
    "def call_segments(row):\n",
    "    plot=False\n",
    "    final_segments = {}\n",
    "    segment_bounds = collections.defaultdict(set)\n",
    "    max_iter= 10\n",
    "    for chromosome in chrom_order:\n",
    "\n",
    "        data = row[chromosome].sort_index()\n",
    "\n",
    "        p = 0.05\n",
    "        shuffles=10000\n",
    "        L = segment( data.values,p=p,shuffles=shuffles )\n",
    "        S = validate( data.values, L, p=p,shuffles=shuffles)\n",
    "\n",
    "        segments = list( (start, end) for start, end in list(more_itertools.windowed(S,2) ))\n",
    "        #segments.append((segments[-1][1],len(data)-1))\n",
    "        orig_segs = segments\n",
    "        prev_len = None\n",
    "\n",
    "        #print(segments)\n",
    "        prev_bps = S\n",
    "        iteration = 0\n",
    "        while (prev_len is None or prev_len != len(prev_bps)) and len(segments)>1 and iteration<max_iter:\n",
    "\n",
    "            bps = []\n",
    "            new_segments=[]\n",
    "            prev=0\n",
    "            #print('Starting solution:')\n",
    "            #print(segments)\n",
    "            prev_len = len(prev_bps)\n",
    "            for breakpoint, delta_cn in zip(prev_bps[1:], np.diff( [data.iloc[start:end].median() for start, end in segments] )):\n",
    "                if abs(delta_cn)>0.6:\n",
    "                    bps.append(breakpoint)\n",
    "                    #rint((prev,breakpoint), delta_cn)\n",
    "                    new_segments.append((prev,breakpoint))\n",
    "                    prev=breakpoint\n",
    "            # Add breakpoint to end:\n",
    "            #new_segments.append((prev,len(data)-1))\n",
    "            segments = new_segments\n",
    "            #print('Current solution:')\n",
    "            if not 0 in bps:\n",
    "                bps_including_ends = [0]+bps\n",
    "            else:\n",
    "                bps_including_ends = bps\n",
    "            if bps_including_ends[-1] != len(data)-1:\n",
    "                bps_including_ends+=[len(data)-1]\n",
    "\n",
    "\n",
    "            called_segment_indices = list(more_itertools.windowed(bps_including_ends,2) )\n",
    "            segments = called_segment_indices\n",
    "            #print(segments, bps_including_ends)\n",
    "            prev_bps = bps_including_ends\n",
    "            iteration+=1\n",
    "        \n",
    "        for bp in bps_including_ends:\n",
    "            segment_bounds[chromosome].add(bp)\n",
    "                \n",
    "        if plot:\n",
    "            fig,ax = plt.subplots( figsize=(15,2))\n",
    "            ax.scatter(data.index, data.values,s=1, c='grey')\n",
    "            for start,end in orig_segs:\n",
    "                plt.axvline(data.index[start],c='k',ls=':',lw=1)\n",
    "                plt.axvline(data.index[end-1],c='k',ls=':',lw=1)\n",
    "            for x in segment_bounds[chromosome]:\n",
    "                plt.axvline(data.index[x],c='r')\n",
    "            plt.title(chromosome)\n",
    "            plt.show()\n",
    "        final_segments[chromosome] = called_segment_indices\n",
    "    return final_segments, row.name\n",
    "workers = Pool(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage,fcluster\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Roughly cluster the cells to generate groups from which to extract segment calls..\n",
    "hand_picked_thresholds = {\n",
    "    'chr1':3,\n",
    "    'chr2':7,\n",
    "    'chr3':3,\n",
    "    'chr4':2,\n",
    "    'chr5':1,\n",
    "    'chr7':2,\n",
    "    'chr8':7,\n",
    "    'chr9':6,\n",
    "    'chr10':4,\n",
    "    'chr11':2,\n",
    "    'chr12':3,\n",
    "    'chr18':5,\n",
    "    'chrX':5    \n",
    "}\n",
    "\n",
    "MAXCP=4\n",
    "segment_bounds = collections.defaultdict(set)\n",
    "segment_calls = []\n",
    "for chromosome in chrom_order:\n",
    "    d = df_wo_alleles_gc_corr[selected_cells_for_segmentation][chromosome].clip(0,MAXCP) \n",
    "    L = linkage(d, method='ward')\n",
    "\n",
    "    scores = []\n",
    "    thresholds = list(range(1,12))\n",
    "    cluster_count = []\n",
    "\n",
    "    max_value = None\n",
    "    max_threshold = None\n",
    "    max_clustering = None\n",
    "    for t in thresholds:\n",
    "        z = fcluster(L, t ,'maxclust')\n",
    "        cluster_count.append(len(set(z)))\n",
    "        try:\n",
    "            scores.append( sklearn.metrics.silhouette_score(d,z) )\n",
    "        except Exception as e:\n",
    "            scores.append(0)\n",
    "            pass\n",
    "        \n",
    "        if chromosome in hand_picked_thresholds:\n",
    "            if t==hand_picked_thresholds[chromosome]:\n",
    "                max_value = scores[-1]\n",
    "                max_clustering = z\n",
    "                max_threshold = t\n",
    "                print(t)\n",
    "\n",
    "        elif max_value is None or scores[-1]>max_value :\n",
    "            max_value = scores[-1]\n",
    "            max_clustering = z\n",
    "            max_threshold = t\n",
    "\n",
    "\n",
    "    plt.plot(thresholds,scores)\n",
    "    plt.title(chromosome)\n",
    "    plt.gca().axvline(max_threshold,c='r')\n",
    "    plt.show()\n",
    "    \n",
    "    assignments = max_clustering\n",
    "    cdf = pd.DataFrame( [assignments],  columns=d.index )\n",
    "    cdf, lut = createRowColorDataFrame(cdf.T)\n",
    "\n",
    "    sns.clustermap( d.sort_index(1),\n",
    "                   col_cluster= False, row_cluster=True, method= 'ward', vmax=MAXCP, row_colors=cdf, figsize=(20,40))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    assignments = max_clustering\n",
    "    \n",
    "    delta_cn_hist= collections.Counter()\n",
    "    fig, axes = plt.subplots(len(set(assignments)),1,figsize=(8,1 + len(set(assignments))), sharex=True, sharey=True, squeeze=False)\n",
    "    \n",
    "    for ax_col,clust in zip(axes, sorted(list(set(assignments)))):\n",
    "        ax = ax_col[0]\n",
    "        ax.set_title(f'{chromosome}, cluster {clust}')\n",
    "        data = d[assignments==clust].median().sort_index(0)\n",
    "\n",
    "        p = 0.005\n",
    "\n",
    "        sample = data.values\n",
    "        L = segment(  sample,p=p )\n",
    "\n",
    "        # Copy number per segment:\n",
    "        S = validate(sample, L,p=p)\n",
    "        \n",
    "        ax.set_ylim(0, MAXCP+0.5)\n",
    "        #draw_segmented_data(sample,  S, title=f'{chromosome}, cluster {clust}', ax=ax)\n",
    "\n",
    "        segments = list(more_itertools.windowed(S,2) )\n",
    "        \n",
    "        bps = []\n",
    "        # @todo: this code has a bug\n",
    "        for breakpoint, delta_cn in zip(S[1:], np.diff( [data.iloc[start:end].median() for start, end in segments] )):\n",
    "            delta_cn_hist[delta_cn] += 1\n",
    "\n",
    "            if abs(delta_cn)>0.6:\n",
    "                #egment_bounds[chromosome][data.index[min(breakpoint,len(data)-1)]]+=len(data)\n",
    "                bps.append(breakpoint)\n",
    "        \n",
    "        \n",
    "        bps_including_ends = [1]+bps+[len(data)-2]\n",
    "        \n",
    "        called_segment_indices = list(more_itertools.windowed(bps_including_ends,2) )\n",
    "        \n",
    "        for bp in bps_including_ends:\n",
    "            ax.axvline(np.array(data.index.values, dtype=int)[bp] * bin_size, c='r')\n",
    "            segment_bounds[chromosome].add(bp)\n",
    "            \n",
    "        for (start, end) in called_segment_indices:\n",
    "            \n",
    "            data_in_seg = data[start:end]\n",
    "            \n",
    "            color = 'grey'\n",
    "            if data_in_seg.median()>2.5:\n",
    "                color='r'\n",
    "            if data_in_seg.median()<1.5:\n",
    "                color='b'\n",
    "            \n",
    "            ax.scatter( np.array(data_in_seg.index.values, dtype=int)*bin_size, data_in_seg.values, s=4,c=color  )\n",
    "        \n",
    "        ax.set_ylabel('copy number')\n",
    "        sns.despine(ax=ax)\n",
    "        \n",
    "        for cp in range(1,MAXCP+1):\n",
    "            ax.axhline(cp,c='k',lw=0.5)\n",
    "    \n",
    "        \n",
    "    ax.set_xlabel('position')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(f'./segments/{chromosome}.png',dpi=100)\n",
    "    plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (df['allele1'].loc[:,sbins]['chr18'].sort_index(1).iloc[:,0:7].sum(1)+\n",
    "    df['allele1'].loc[:,sbins]['chr18'].sort_index(1).iloc[:,69:76].sum(1))/(\n",
    "        \n",
    "    (df['allele2'].loc[:,sbins]['chr18'].sort_index(1).iloc[:,0:7].sum(1)+\n",
    "    df['allele2'].loc[:,sbins]['chr18'].sort_index(1).iloc[:,69:76].sum(1))+\n",
    "    (df['allele1'].loc[:,sbins]['chr18'].sort_index(1).iloc[:,0:7].sum(1)+\n",
    "    df['allele1'].loc[:,sbins]['chr18'].sort_index(1).iloc[:,69:76].sum(1))\n",
    ")\n",
    "\n",
    "c = c.loc[df_wo_alleles_gc_corr[selected_cells_for_segmentation].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = 2\n",
    "plt.scatter( \n",
    "    \n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[cid,:].index,\n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[cid,:]\n",
    "\n",
    "\n",
    ")\n",
    "plt.show()\n",
    "plt.scatter(\n",
    "        df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[cid,:].index,\n",
    "        df['allele1'].loc[:,sbins]['chr9'].sort_index(1).loc[df_wo_alleles_gc_corr[selected_cells_for_segmentation].index].iloc[cid]\n",
    "\n",
    "        )\n",
    "    \n",
    "plt.scatter(\n",
    "        df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[cid,:].index,\n",
    "        -df['allele2'].loc[:,sbins]['chr9'].sort_index(1).loc[df_wo_alleles_gc_corr[selected_cells_for_segmentation].index].iloc[cid]\n",
    "\n",
    "        )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = collections.Counter( df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].idxmax(axis=1) )\n",
    "plt.scatter(list(q.keys()),list(q.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr6'].mean(1), bins=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,delta:6].mean(1), bins=50)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(\n",
    "    pd.concat((\n",
    "        df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,delta:7-delta], \n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,69+delta:76-delta]\n",
    "    ),axis=1\n",
    "    ).mean(1), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta = 0\n",
    "\n",
    "plt.scatter( \n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,delta:7-delta].mean(1), \n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,69+delta:76-delta].mean(1)\n",
    ")\n",
    "plt.show()\n",
    "plt.scatter( \n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,delta:6-delta].mean(1), \n",
    "    pd.concat((\n",
    "        df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,delta:7-delta], \n",
    "    df_wo_alleles_gc_corr[selected_cells_for_segmentation]['chr9'].iloc[:,69+delta:76-delta]\n",
    "    ),axis=1\n",
    "    ).mean(1),\n",
    "    c=c\n",
    "    \n",
    ")\n",
    "plt.xlim(1,4)\n",
    "plt.ylim(1,4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_bounds =  {\n",
    "            'chr1': { 15, 155, 157, 201, 436},\n",
    "             'chr2': {0, 135, 467},\n",
    "             'chr3': {0, 252, 387},\n",
    "             'chr4': {0, 372},\n",
    "             'chr5': {0, 348},\n",
    "             'chr6': {0, 55, 66, 68, 333},\n",
    "             'chr7': {0, 302},\n",
    "             'chr8': {0, 5, 8, 82, 123, 279},\n",
    "             'chr9': {0, 7, 8, 69, 76, 216},\n",
    "             'chr10': {0, 91, 255},\n",
    "             'chr11': {0, 256},\n",
    "             'chr12': {0, 142, 181, 258},\n",
    "             'chr13': {0, 190},\n",
    "             'chr14': {0, 173},\n",
    "             'chr15': {0, 10, 16, 153},\n",
    "             'chr16': {0, 150},\n",
    "             'chr17': {0, 97, 152},\n",
    "             'chr18': {0, 29, 32, 37, 42, 147},\n",
    "             'chr19': {0, 107},\n",
    "             'chr20': {0, 116},\n",
    "             'chr21': {0, 63},\n",
    "             'chr22': {0, 64},\n",
    "             'chrX': {0, 292}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_segments = []\n",
    "min_segment_size = 5\n",
    "for chrom, bounds_set in segment_bounds.items():\n",
    "    bounds_list=sorted(list(bounds_set))\n",
    "    for seg in list( more_itertools.windowed(bounds_list,2) ):\n",
    "        if np.abs(np.diff(seg))[0] < min_segment_size:\n",
    "            continue\n",
    "        print(chrom, seg, np.abs(np.diff(seg))[0] )\n",
    "        seg = (seg[0],seg[1]) # the range is exclusive\n",
    "        final_segments.append( (chrom,seg) )\n",
    "print(final_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variances = {}\n",
    "MAXCP=10 # just to not clip the values here\n",
    "for chrom, seg in final_segments:\n",
    "    if not (chrom,seg) in segmented_matrix:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    diploid_cells_for_bin = segmented_matrix[chrom,seg]==segmented_matrix[chrom,seg].mode()[0]\n",
    "    diploid_cells_for_bin=diploid_cells_for_bin[diploid_cells_for_bin].index\n",
    "    #plt.hist(np.clip(d.loc[diploid_cells_for_bin][chrom].iloc[:,seg[0]:seg[1]],0, MAXCP  ).median(1).values.flatten(),bins=30)\n",
    "    #plt.title(f'{chrom},{seg}')\n",
    "    #plt.show()\n",
    "    variances[chrom,seg] = np.clip(d.loc[diploid_cells_for_bin][chrom].iloc[:,seg[0]:seg[1]],0, MAXCP  ).median(1).values.flatten().var()\n",
    "\n",
    "vlim = 0.02\n",
    "vf = pd.DataFrame({'variance':variances})\n",
    "\n",
    "\n",
    "variance_selected_bins = vf[ vf['variance']<=vlim ].index\n",
    "\n",
    "vf.plot.bar(figsize=(20,4))\n",
    "ax = plt.gca()\n",
    "ax.axhline(vlim,c='red')\n",
    "plt.show()\n",
    "\n",
    "vf['variance'].plot.hist()\n",
    "ax = plt.gca()\n",
    "ax.axvline(vlim,c='red')\n",
    "\n",
    "\n",
    "final_segments = []\n",
    "min_segment_size = 5\n",
    "for chrom, bounds_set in segment_bounds.items():\n",
    "    bounds_list=sorted(list(bounds_set))\n",
    "    for seg in list( more_itertools.windowed(bounds_list,2) ):\n",
    "        if not (chrom,seg) in variance_selected_bins:\n",
    "            continue\n",
    "        print(chrom, seg, np.abs(np.diff(seg))[0] )\n",
    "        seg = (seg[0],seg[1]) # the range is exclusive\n",
    "        final_segments.append( (chrom,seg) )\n",
    "print(final_segments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Segment the copy number matrix:\n",
    "\n",
    "MAXCP=4\n",
    "\n",
    "d = df_wo_alleles_gc_corr[selected_cells_for_segmentation]\n",
    "\n",
    "segmented_matrix_floating=[]\n",
    "segmented_matrix = []\n",
    "segmented_matrix_labels = []\n",
    "\n",
    "min_segment_size = 5\n",
    "\n",
    "for chrom, seg in final_segments:\n",
    "\n",
    "    print(chrom,seg)\n",
    "    segmented_matrix_floating.append(np.clip(d[chrom].iloc[:,seg[0]:seg[1]].median(1),0, MAXCP  ))\n",
    "    segmented_matrix.append(np.clip(d[chrom].iloc[:,seg[0]:seg[1]].median(1).round(0),0, MAXCP  ))\n",
    "    segmented_matrix_labels.append((chrom,seg))\n",
    "\n",
    "segmented_matrix = pd.concat(segmented_matrix,1)\n",
    "segmented_matrix.columns = segmented_matrix_labels\n",
    "\n",
    "segmented_matrix_floating = pd.concat(segmented_matrix_floating,1)\n",
    "segmented_matrix_floating.columns = segmented_matrix_labels\n",
    "\n",
    "columns_with_info = [len(segmented_matrix[column].unique())>1 for column in segmented_matrix]\n",
    "segmented_matrix = segmented_matrix.loc[:,columns_with_info]\n",
    "segmented_matrix_labels = np.array(segmented_matrix_labels)[columns_with_info]\n",
    "segmented_matrix.columns= pd.MultiIndex.from_tuples(segmented_matrix.columns)\n",
    "\n",
    "cnv_clusters = collections.Counter()\n",
    "cell_to_unfiltered_cnv = collections.defaultdict(list)\n",
    "for cell,row in segmented_matrix.iterrows():\n",
    "    cnv_clusters[tuple(row)]+=1\n",
    "    cell_to_unfiltered_cnv[tuple(row)].append(cell)\n",
    "\n",
    "keep_clusters = []\n",
    "cell_order = []\n",
    "cell_cluster_names = []\n",
    "current_cluster_name = 1\n",
    "min_cells_per_cluster=2\n",
    "\n",
    "median_profiles = []\n",
    "\n",
    "for ci,(cluster, obs) in enumerate( cnv_clusters.most_common() ):\n",
    "    if obs>=min_cells_per_cluster:\n",
    "        \n",
    "        keep_clusters.append(cluster)\n",
    "        \n",
    "        cells_in_cluster = []\n",
    "        for cell in cell_to_unfiltered_cnv[cluster]:\n",
    "            cells_in_cluster.append(cell)\n",
    "        \n",
    "        # Cluster the cells ..\n",
    "        cells_in_cluster = np.array(cells_in_cluster)\n",
    "        \n",
    "        cells_in_cluster = cells_in_cluster[leaves_list( \n",
    "                linkage(d.loc[cells_in_cluster], method='ward',optimal_ordering=True)\n",
    "        )]\n",
    "        print(obs, len(cells_in_cluster))\n",
    "        median_profiles.append( d.loc[cells_in_cluster].median(0) )\n",
    "        \n",
    "        cell_order += list(cells_in_cluster)\n",
    "        cell_cluster_names += [current_cluster_name]*len(cells_in_cluster)\n",
    "        \n",
    "        current_cluster_name+=1\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(d.loc[cells_in_cluster].sort_index(1)[chrom_order] ,ax=ax, vmax=MAXCP,cmap='bwr')\n",
    "        plt.savefig(f'./cluster_{ci}.png')\n",
    "        plt.close()\n",
    "    \n",
    "print(f'{current_cluster_name} clusters identified')\n",
    "print(f'{segmented_matrix.shape[0]} cells assigned to a cluster')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations between the segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(segmented_matrix_floating.corr(),yticklabels=True,xticklabels=True,method='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def createRowColorDataFrame( discreteStatesDataFrame, nanColor =(0,0,0), predeterminedColorMapping={},seed=1337 ):\n",
    "\n",
    "    \"\"\" Create color dataframe for use with seaborn clustermap\n",
    "\n",
    "    Args:\n",
    "        discreteStatesDataFrame (pd.DataFrame) : Dataframe containing the data to convert to colors, like:  pd.DataFrame( [['A','x'],['A','y']],index=['A','B'], columns=['First', 'Second'] )\n",
    "\n",
    "        nanColor(tuple) : Color for records having an NAN\n",
    "\n",
    "        predeterminedColorMapping(dict) : Supply class colors here (optional)\n",
    "\n",
    "    Returns:\n",
    "        discreteColorMatrix (pd.DataFrame) : Dataframe to pass to seaborn clustermap row_colors, or col_colors\n",
    "        \n",
    "        luts (dict) : class->color mapping\n",
    "    \"\"\"\n",
    "    # Should look like:\n",
    "    # discreteStatesDataFrame = pd.DataFrame( [['A','x'],['A','y']],index=['A','B'], columns=['First', 'Second'] )\n",
    "    colorMatrix = []\n",
    "    luts = {}\n",
    "    random.seed(seed)\n",
    "    for column in discreteStatesDataFrame:\n",
    "        states = [x for x in discreteStatesDataFrame[column].unique() if not pd.isnull(x)]\n",
    "        undeterminedColorStates = [x for x in discreteStatesDataFrame[column].unique() if not pd.isnull(x) and not x in predeterminedColorMapping]\n",
    "\n",
    "        cols = sns.color_palette('hls',len(undeterminedColorStates))\n",
    "        random.shuffle(cols)\n",
    "        #lut = { i:sns.color_palette('bright').jet(x) for i,x in zip(states, np.linspace(0,1,len(states)) )}\n",
    "        lut = { state:cols[i] for i,state in enumerate(undeterminedColorStates) }\n",
    "        lut.update({key:value for key,value in predeterminedColorMapping.items() if key in states})\n",
    "        lut[np.nan] = nanColor\n",
    "        colorMatrix.append( [ nanColor if pd.isnull(x) else lut[x] for x in  discreteStatesDataFrame[column] ] )\n",
    "        luts[column] = lut\n",
    "    discreteColorMatrix = pd.DataFrame(colorMatrix, index=discreteStatesDataFrame.columns, columns=discreteStatesDataFrame.index ).transpose()\n",
    "    return discreteColorMatrix, luts\n",
    "\n",
    "cell_annot_df = pd.DataFrame( [cell_cluster_names, [cell.split('-')[0] for cell in cell_order] ],  columns=cell_order )\n",
    "cell_annot_df, lut = createRowColorDataFrame(cell_annot_df.T)\n",
    "\n",
    "\n",
    "bin_annot_df = pd.DataFrame( [[chrom for chrom, pos in d.sort_index(1)[chrom_order].columns] ],  columns=d.sort_index(1)[chrom_order].loc[cell_order].columns )\n",
    "bin_annot_df, lut = createRowColorDataFrame(bin_annot_df.T)\n",
    "\n",
    "sns.clustermap(d.sort_index(1)[chrom_order].loc[cell_order], vmax=4,cmap='bwr', row_colors=cell_annot_df, col_colors=bin_annot_df,figsize=(20,30), row_cluster=False, col_cluster=False)\n",
    "plt.savefig(f'./cluster_sorted.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_annot_df['cluster'] = cell_cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T15:48:28.626193Z",
     "start_time": "2020-02-12T15:48:28.565967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add allele frequency data for chromosome 18 and chromosome 4\n",
    "baf_18 = df['allele1'].loc[:,sbins]['chr18'].sum(1) / (df['allele1'].loc[:,sbins]['chr18'].sum(1)+df['allele2'].loc[:,sbins]['chr18'].sum(1))\n",
    "baf_4 = df['allele1'].loc[:,sbins]['chr4'].sum(1) / (df['allele1'].loc[:,sbins]['chr4'].sum(1)+df['allele2'].loc[:,sbins]['chr4'].sum(1))\n",
    "baf_9 = df['allele1'].loc[:,sbins]['chr9'].sum(1) / (df['allele1'].loc[:,sbins]['chr9'].sum(1)+df['allele2'].loc[:,sbins]['chr9'].sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T15:49:08.422345Z",
     "start_time": "2020-02-12T15:49:08.400899Z"
    }
   },
   "outputs": [],
   "source": [
    "bafs = pd.concat([baf_4, baf_9, baf_18],axis=1)\n",
    "bafs.columns=['baf_4','baf_9','baf_18']\n",
    "bafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baf_segmented_matrix = []\n",
    "baf_segmented_matrix_labels = []\n",
    "baf_min_segment_size = 0\n",
    "\n",
    "acn_matrix = []\n",
    "\n",
    "for chrom,seg in segmented_matrix:\n",
    "\n",
    "    if not chrom in ['chr4']: #, 'chr9', 'chr18']: # @todo\n",
    "        continue\n",
    "\n",
    "    if np.abs(np.diff(seg))[0] < min_segment_size:\n",
    "        continue\n",
    "    seg_baf = df['allele1'].loc[:,sbins][chrom].iloc[:,seg[0]:seg[1]].sum(1) / (\n",
    "\n",
    "\n",
    "        df['allele1'].loc[:,sbins][chrom].iloc[:,seg[0]:seg[1]].sum(1)+\n",
    "        df['allele2'].loc[:,sbins][chrom].iloc[:,seg[0]:seg[1]].sum(1)\n",
    "    )\n",
    "    baf_segmented_matrix.append(seg_baf)\n",
    "    baf_segmented_matrix_labels.append((chrom,seg))\n",
    "\n",
    "    cn = segmented_matrix[chrom,seg]\n",
    "\n",
    "\n",
    "baf_segmented_matrix = pd.concat(baf_segmented_matrix,1)\n",
    "\n",
    "baf_columns_with_info = [len(baf_segmented_matrix[column].unique())>1 for column in baf_segmented_matrix]\n",
    "baf_segmented_matrix = baf_segmented_matrix.loc[:,baf_columns_with_info]\n",
    "baf_segmented_matrix_labels = np.array(baf_segmented_matrix_labels)[baf_columns_with_info]\n",
    "baf_segmented_matrix = pd.DataFrame(baf_segmented_matrix)\n",
    "baf_segmented_matrix.columns = baf_segmented_matrix_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "# Extract copies per allele \n",
    "\n",
    "\n",
    "for col in baf_segmented_matrix.columns:\n",
    "\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    \n",
    "    for cell, row in baf_segmented_matrix.iterrows():\n",
    "        if not cell in segmented_matrix.index:\n",
    "            continue\n",
    "        for k, baf in row.iteritems():\n",
    "            if k!=col:\n",
    "                continue\n",
    "            \n",
    "            x.append(baf)\n",
    "            y.append(segmented_matrix_floating.loc[cell][k])\n",
    "\n",
    "    jitter=0\n",
    "    fig, axes = plt.subplots(2,1,sharex=True,figsize=(4,6))\n",
    "    axes[0].hist(y,bins=100)\n",
    "    axes[0].set_ylabel('# cells in bin' )\n",
    "    ax = axes[1]\n",
    "    \n",
    "    ax.scatter(y,x, s=1,alpha=0.1) #+np.random.random(len(x))*jitter -0.5*jitter , \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylim(-0.05,1.05)\n",
    "    plt.title(f' {col[0]}:{col[1][0]}-{col[1][1]}')\n",
    "    ax.set_ylabel('B-allele frequency')\n",
    "    ax.set_xlabel('Estimated copy number')\n",
    "    ax.set_xlim(-0.5,None)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.core.series\n",
    "def baf_and_cn_to_allelic_cn(baf, cn):\n",
    "    \"\"\"\n",
    "    Convert b-allele frequency and total copy number to the copy number of both alleles\n",
    "    \n",
    "    Args:\n",
    "        baf(np.array)\n",
    "        cn(np.array))\n",
    "    Returns\n",
    "        (Allele A cn, Allele B cn)\n",
    "    \"\"\"\n",
    "    \n",
    "    b_allele_cn = np.round(cn*baf,0)\n",
    "    a_allele_cn = cn - b_allele_cn\n",
    "    \n",
    "    for c,allele in zip((a_allele_cn, b_allele_cn),'AB'):\n",
    "        if type(c) is pandas.core.series.Series:\n",
    "            c.name = (c.name[0], allele,(c.name[1]) )#f'{c.name[0]}_{n}:{c.name[1][0]}-{c.name[1][1]}'\n",
    "    \n",
    "    return a_allele_cn, b_allele_cn\n",
    "    \n",
    "baf_and_cn_to_allelic_cn(np.array([0.5,1]),np.array([2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_cn_matrix = pd.concat(\n",
    "pd.DataFrame( baf_and_cn_to_allelic_cn(baf,segmented_matrix[seg]) ) \n",
    "    for seg,baf in baf_segmented_matrix.loc[segmented_matrix.index].T.iterrows()\n",
    "    ).T\n",
    "\n",
    "allele_cn_matrix.columns = pd.MultiIndex.from_tuples(allele_cn_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns without allele information:\n",
    "non_allele_cn_matrix = segmented_matrix[ \n",
    "    [seg for seg in segmented_matrix if not seg in baf_segmented_matrix.columns] ]\n",
    "non_allele_cn_matrix.columns = pd.MultiIndex.from_tuples([(chrom,'none',(start,end)) for (chrom,(start,end)) in non_allele_cn_matrix.columns])\n",
    "\n",
    "# Format tuple headers to strings:\n",
    "hybrid_allele_cn_matrix = non_allele_cn_matrix.join(allele_cn_matrix) \n",
    "hybrid_allele_cn_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_OBS = 1\n",
    "states = collections.Counter()\n",
    "\n",
    "for cell, row in hybrid_allele_cn_matrix.iterrows():\n",
    "    state = tuple(row)\n",
    "    states[state] += 1\n",
    "\n",
    "state_ids = {}\n",
    "cell_to_state = {}\n",
    "current_state_id = 1\n",
    "assigned_cells = 0\n",
    "state_bin_info = []\n",
    "#'chromosome', 'cluster', 'binIndex', 'startCoordinate', 'endCoordinate'\n",
    "# _A, _B when allelic\n",
    "cell_order = []\n",
    "for state,obs in states.most_common():\n",
    "    if obs<MIN_OBS:\n",
    "        continue\n",
    "        \n",
    "    for cell, row in hybrid_allele_cn_matrix.iterrows():\n",
    "        cell_state = tuple(row)\n",
    "        if cell_state == state:\n",
    "            cell_order.append(cell)\n",
    "        \n",
    "    current_state_id+=1\n",
    "    assigned_cells+=obs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the bin indices to coordinates:\n",
    "hybrid_allele_cn_matrix.columns = pd.MultiIndex.from_tuples(( (chrom, allele, (start*bin_size, end*bin_size)) \n",
    "                           for chrom, allele, (start, end) in hybrid_allele_cn_matrix.columns)\n",
    "                         )\n",
    "\n",
    "hybrid_allele_cn_matrix[\n",
    "    [chrom for chrom in chrom_order if chrom in hybrid_allele_cn_matrix.columns.levels[0] \n",
    "    ]].to_pickle('./figures/resources/hybrid_cn_matrix_reduced_segments_variance.pickle.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_allele_cn_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = pd.concat(\n",
    "    (\n",
    "    df['allele1']['chr4'].loc[cell_order],\n",
    "    df['allele2']['chr4'].loc[cell_order],\n",
    "        \n",
    "    df['allele1']['chr18'].loc[cell_order],\n",
    "    df['allele2']['chr18'].loc[cell_order],\n",
    "    d.sort_index(1)[chrom_order].loc[cell_order]\n",
    "    ), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_allele_cn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_annot_df.to_csv('cell_clusters.csv')\n",
    "hybrid_allele_cn_matrix.to_csv('hybrid_allele_cn_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(sf, vmax=4,cmap='bwr',figsize=(20,30), row_cluster=False, col_cluster=False)\n",
    "\n",
    "plt.savefig(f'./cluster_sorted_with_bafs.png', dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baf_segmented_matrix.plot.hist(bins=100)\n",
    "b_loss = baf_segmented_matrix[baf_segmented_matrix[('chr4', (1, 371))]<0.1].index\n",
    "a_loss = baf_segmented_matrix[baf_segmented_matrix[('chr4', (1, 371))]>0.9].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baf_segmented_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attemp to re-cluster the rejected cells\n",
    "\n",
    "\n",
    "def extract_median_matrix_segments(d, cnv_clusters, min_segment_size = 5,MAXCP=4)\n",
    "    \n",
    "    segmented_matrix_floating=[]\n",
    "    segmented_matrix = []\n",
    "    segmented_matrix_labels = []\n",
    "\n",
    "    min_segment_size = 5\n",
    "\n",
    "    for chrom, seg in final_segments:\n",
    "\n",
    "        print(chrom,seg)\n",
    "        segmented_matrix_floating.append(np.clip(d[chrom].iloc[:,seg[0]:seg[1]].median(1),0, MAXCP  ))\n",
    "        segmented_matrix.append(np.clip(d[chrom].iloc[:,seg[0]:seg[1]].median(1).round(0),0, MAXCP  ))\n",
    "        segmented_matrix_labels.append((chrom,seg))\n",
    "\n",
    "    return \n",
    "    \n",
    "segment_matrix( df_wo_alleles_gc_corr[  noise_predictions<threshold  ] )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baf_segmented_matrix.to_pickle('bafs_segmented.pickle.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom= 'chr18'\n",
    "sns.heatmap( \n",
    "    pd.concat([\n",
    "    df['allele1'][chrom].loc[cell_annot_df.index].fillna(0) / (\n",
    "        df['allele1'][chrom].loc[cell_annot_df.index].fillna(0)+\n",
    "        df['allele2'][chrom].loc[cell_annot_df.index].fillna(0)),\n",
    "        df_wo_alleles_gc_corr[chrom].loc[cell_annot_df.index]/MAXCP,\n",
    "    \n",
    "        \n",
    "        baf_segmented_matrix.loc[cell_annot_df.index]\n",
    "        \n",
    "    ],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(15,80))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.clustermap( pd.concat([\n",
    "    pd.concat([\n",
    "        df_wo_alleles_gc_corr[chrom].loc[cell_annot_df.index]/MAXCP,\n",
    "    df['allele1'][chrom].loc[cell_annot_df.index].fillna(0) / (\n",
    "        df['allele1'][chrom].loc[cell_annot_df.index].fillna(0)+\n",
    "        df['allele2'][chrom].loc[cell_annot_df.index].fillna(0)),\n",
    "        \n",
    "    \n",
    "        \n",
    "    ],axis=1).fillna(0.5)\n",
    "    for chrom in ['chr4','chr18','chr9']\n",
    "\n",
    "],axis=1) , figsize=(15,80), col_cluster=False, vmax=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "af_mat = []\n",
    "for cluster in list(set(cell_annot_df['cluster']) ):\n",
    "    cells = cell_annot_df[cell_annot_df['cluster']==cluster].index\n",
    "\n",
    "    # Show allele frequencies for single cluster:\n",
    "    df['allele1']['chr18'].loc[cells].fillna(0).mean().plot()\n",
    "    (-df['allele2']['chr18'].loc[cells].fillna(0).mean()).plot()\n",
    "    \n",
    "    af_mat.append( df['allele1']['chr18'].loc[cells].fillna(0)  )\n",
    "    \n",
    "    plt.title(cluster)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T15:52:03.690777Z",
     "start_time": "2020-02-12T15:52:03.132312Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bd =  pd.DataFrame(\n",
    "    [d.loc[cell_order]['chr4'].median(1),\n",
    "     d.loc[cell_order]['chr9'].median(1),\n",
    "   d.loc[cell_order]['chr18'].median(1)\n",
    " ],index=['chr4_median_cn','chr9_median_cn','chr18_median_cn']).T.join(cell_annot_df).join(bafs)\n",
    "#bd.columns[0] = 'chr4_median'\n",
    "bd.plot.scatter(y='chr4_median_cn',x='baf_4',c=bd['cluster'],s=4, alpha=0.5)\n",
    "bd.plot.scatter(y='chr9_median_cn',x='baf_9',c=bd['cluster'],s=4, alpha=0.5)\n",
    "bd.plot.scatter(y='chr18_median_cn',x='chr9_median_cn',c=bd['cluster'],s=4, alpha=0.5)\n",
    "\n",
    "bd.plot.scatter(y='chr18_median_cn',x='baf_18',c=bd['cluster'],s=4, alpha=0.5)\n",
    "bd.plot.scatter(y='baf_4',x='baf_18',c=bd['cluster'],s=4, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:41:20.817192Z",
     "start_time": "2020-02-12T16:41:20.710115Z"
    }
   },
   "outputs": [],
   "source": [
    "segmented_b_allele_matrix = []\n",
    "segmented_b_allele_matrix_names = []\n",
    "for contig, (start, end) in segmented_matrix_labels:\n",
    "    if not contig in ('chr9','chr4','chr18'):\n",
    "        continue\n",
    "    print(contig, start, end)\n",
    "    \n",
    "    baf = df['allele1'][contig].iloc[:,start:end].sum(1) / (df['allele1'][contig].iloc[:,start:end].sum(1)+df['allele2'][contig].iloc[:,start:end].sum(1))\n",
    "    segmented_b_allele_matrix.append(baf)\n",
    "    segmented_b_allele_matrix_names.append(('baf', contig, (start, end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:41:20.942964Z",
     "start_time": "2020-02-12T16:41:20.924323Z"
    }
   },
   "outputs": [],
   "source": [
    "segmented_b_allele_matrix = pd.concat( segmented_b_allele_matrix, axis=1 ).loc[cell_order].fillna(0.5)\n",
    "segmented_b_allele_matrix.columns = pd.MultiIndex.from_tuples(segmented_b_allele_matrix_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:41:31.384548Z",
     "start_time": "2020-02-12T16:41:23.331634Z"
    }
   },
   "outputs": [],
   "source": [
    "b_allele_red = tsne.fit_transform(segmented_b_allele_matrix.join(segmented_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:42:23.365469Z",
     "start_time": "2020-02-12T16:42:22.767816Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bd =  pd.DataFrame(\n",
    "    [d.loc[cell_order]['chr4'].median(1),\n",
    "     d.loc[cell_order]['chr9'].median(1),\n",
    "   d.loc[cell_order]['chr18'].median(1),\n",
    "\n",
    " ],index=['chr4_median_cn','chr9_median_cn','chr18_median_cn']).T.join(cell_annot_df).join(bafs)\n",
    "\n",
    "bd['tsne_0'] =  b_allele_red[:,0]\n",
    "bd['tsne_1'] =  b_allele_red[:,1]\n",
    "\n",
    "#bd.columns[0] = 'chr4_median'\n",
    "bd.plot.scatter(y='chr4_median_cn',x='baf_4',c=bd['cluster'],s=4, alpha=0.5)\n",
    "bd.plot.scatter(y='chr9_median_cn',x='baf_9',c=bd['cluster'],s=4, alpha=0.5)\n",
    "bd.plot.scatter(y='chr18_median_cn',x='chr9_median_cn',c=bd['cluster'],s=4, alpha=0.5)\n",
    "\n",
    "bd.plot.scatter(y='chr18_median_cn',x='baf_18',c=bd['cluster'],s=4, alpha=0.5)\n",
    "bd.plot.scatter(y='baf_4',x='baf_18',c=bd['cluster'],s=4, alpha=0.5)\n",
    "bd.plot.scatter(y='tsne_0',x='tsne_1',c=bd['cluster'],s=4, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:46:44.374512Z",
     "start_time": "2020-02-12T16:46:44.366286Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_bd = bd.join(segmented_b_allele_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:46:45.420395Z",
     "start_time": "2020-02-12T16:46:44.899550Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in segmented_b_allele_matrix.columns:\n",
    "    merged_bd.plot.scatter(y='tsne_0',x='tsne_1',c=merged_bd[column],s=4, alpha=0.5,colormap='viridis',vmax=1,vmin=0)\n",
    "    plt.title(f'{column[1]}: {column[2][0]}:{column[2][1]}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:49:58.065606Z",
     "start_time": "2020-02-12T16:49:58.062019Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:54:14.001153Z",
     "start_time": "2020-02-12T16:54:13.443449Z"
    }
   },
   "outputs": [],
   "source": [
    "for column in segmented_b_allele_matrix.columns:\n",
    "    cell_annot_df[f'{column[0]}: {column[1][0]}:{column[1][1]}'] = [cmap(c) for c in merged_bd[column]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:54:43.223181Z",
     "start_time": "2020-02-12T16:54:16.324316Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(df_int_dist.sort_index(1)[chrom_order].loc[cell_order], vmax=4,cmap='bwr', row_colors=cell_annot_df, col_colors=bin_annot_df,figsize=(20,30), row_cluster=False, col_cluster=False)\n",
    "plt.savefig(f'./cluster_sorted_annot_baf.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:51:35.856494Z",
     "start_time": "2020-02-12T16:51:25.939267Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.savefig(f'./cluster_sorted_annot_baf.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:36:35.526987Z",
     "start_time": "2020-02-12T14:36:34.915172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract B-allele frequencies per segment\n",
    "\n",
    " df['allele1']['chr18'].sum(1) / (df['allele1']['chr18'].sum(1)+df['allele2']['chr18'].sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T12:36:09.098480Z",
     "start_time": "2020-02-11T12:36:09.092493Z"
    }
   },
   "outputs": [],
   "source": [
    "segmented_matrix_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T12:36:35.208372Z",
     "start_time": "2020-02-11T12:36:35.167419Z"
    }
   },
   "outputs": [],
   "source": [
    "segmented_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:55:32.600888Z",
     "start_time": "2020-02-10T15:55:32.236195Z"
    }
   },
   "outputs": [],
   "source": [
    "df_int_dist.loc[clean_cells][contig].to_pickle('./clean_cell_data.pickle.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:21:27.431449Z",
     "start_time": "2020-02-10T15:21:27.290054Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_matrix = pd.DataFrame( cluster_assignments, columns=df_int_dist.loc[clean_cells].index ).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:21:29.130322Z",
     "start_time": "2020-02-10T15:21:28.997921Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_clusters_dict = {\n",
    "  cluster_vector:cluster_index  for cluster_index, (cluster_vector, obs) in enumerate(\n",
    "        collections.Counter( [ tuple(row.values) for i,row in cnv_matrix.iterrows()] ).most_common()\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:21:29.726857Z",
     "start_time": "2020-02-10T15:21:29.580543Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cell_cnv_clusters = [cnv_clusters_dict.get(tuple(row.values)) for i,row in cnv_matrix.iterrows() if tuple(row.values) in cnv_clusters_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:33:48.804488Z",
     "start_time": "2020-02-10T15:33:26.239564Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_cluster_assignments = fcluster(linkage(cnv_matrix, method='ward',optimal_ordering=True),33,'maxclust')\n",
    "cdf = pd.DataFrame( [assignments],  columns=cnv_matrix.index )\n",
    "cdf, lut = createRowColorDataFrame(cdf.T)\n",
    "\n",
    "d = sns.clustermap( cnv_matrix,\n",
    "               col_cluster= False, row_cluster=True, method= 'ward', row_colors=cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:35:54.471446Z",
     "start_time": "2020-02-10T15:35:54.133430Z"
    }
   },
   "outputs": [],
   "source": [
    "cnv_matrix['cluster'] = cnv_cluster_assignments\n",
    "cm = sns.clustermap( cnv_matrix.sort_values('cluster').drop('cluster',1), col_cluster= False, row_cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:36:43.885640Z",
     "start_time": "2020-02-10T15:36:36.788832Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.heatmap( df_clean.loc[cnv_matrix.sort_values('cluster').drop('cluster',1).index][chrom_order], vmax=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T14:17:51.530561Z",
     "start_time": "2020-01-28T14:17:51.470529Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_int_dist[assignments==1][chrom_order].median().plot(style='.', ms=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T15:42:21.612754Z",
     "start_time": "2020-02-10T15:42:21.555182Z"
    }
   },
   "outputs": [],
   "source": [
    "# determine breakpoints\n",
    "\n",
    "for clust in set(assignments):\n",
    "    fig, ax = plt.subplots()\n",
    "    df_int_dist.loc[clean_cells][assignments==clust].mean().plot()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T13:44:50.450525Z",
     "start_time": "2020-01-28T13:44:50.415994Z"
    }
   },
   "outputs": [],
   "source": [
    "#plt.df_clean[assignments==1]\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap( df_clean.iloc[assignments.argsort()][chrom_order], vmax=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:34:48.316435Z",
     "start_time": "2020-01-17T13:34:48.091576Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for \n",
    "ax.hist( s[chrom_order].iloc[:,15].values, bins=250 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:29:45.822174Z",
     "start_time": "2020-01-17T13:29:43.343425Z"
    }
   },
   "outputs": [],
   "source": [
    "def hist_1d(a):\n",
    "    return np.histogram(a, bins=50, range=(0,5), density=True)[0]\n",
    "\n",
    "counts = np.apply_along_axis(hist_1d, axis=1, arr=s[chrom_order].values.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:29:56.590285Z",
     "start_time": "2020-01-17T13:29:46.704615Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(counts, col_cluster= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T09:26:45.688272Z",
     "start_time": "2020-01-20T09:26:24.368457Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap( s[chrom_order].clip(0,4), col_cluster= False, row_cluster=False, vmax=4, method='ward', cmap='viridis')\n",
    "plt.savefig('./cleaned_cells_orig_200k.png', dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T13:13:03.412143Z",
     "start_time": "2020-01-15T13:13:03.046664Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.median(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T12:12:41.686052Z",
     "start_time": "2020-01-16T12:12:41.676807Z"
    }
   },
   "outputs": [],
   "source": [
    "np.argsort( [(0,1),(2,0),],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T10:19:44.278720Z",
     "start_time": "2020-01-23T10:18:56.939517Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap( ( (df_clean[chrom_order].T/df_clean[chrom_order].median(1))*2).T, col_cluster= False, vmax=5)\n",
    "plt.savefig('./cleaned_cells_reassigned.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering per chromosome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:12:18.571512Z",
     "start_time": "2020-01-14T11:12:17.428492Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.hist( (df_norm_gauss.round().mean(1)), bins=100 )\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:11:33.431226Z",
     "start_time": "2020-01-14T11:11:16.441369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cells sorted by variance\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap( \n",
    "    ( df_norm_gauss.round()-df_norm_gauss).loc[((( df_norm_gauss.round()-df_norm_gauss).var(1))).sort_values(ascending=False).index]\n",
    "    , ax=ax, vmax=0.5, cmap='viridis' )\n",
    "plt.savefig('./residuals.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:11:06.400972Z",
     "start_time": "2020-01-14T11:10:58.498508Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "#gaussian_filter(df_norm, (10,0.01))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap( \n",
    "    df_norm.loc[df_norm_gauss.round().mean(1).sort_values(ascending=False).index]\n",
    "    , ax=ax, vmax=3 )\n",
    "#sns.heatmap( gaussian_filter(df_norm, (10,0.01)).loc[df_norm.var(1).sort_values(ascending=False)[20:200].index], ax=ax, cmap='viridis',vmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T15:05:33.250780Z",
     "start_time": "2020-01-21T14:59:47.465953Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_norm_gauss.loc[ df_norm_gauss.round().mean(1).sort_values(ascending=False).index[:100]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:49:01.145097Z",
     "start_time": "2020-01-14T11:48:59.970192Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm_gauss.loc[ df_norm_gauss.round().mean(1).sort_values(ascending=False).index[:10]].T.plot(alpha=0.3,lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:03:08.909505Z",
     "start_time": "2020-01-14T11:03:00.375148Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.savefig('./variance_cells.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:14:15.145231Z",
     "start_time": "2020-01-14T10:13:39.319190Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "sns.clustermap( np.clip(df_norm,0,4) , cmap= 'viridis', row_cluster=True, col_cluster= False)\n",
    "plt.savefig('./all_cells.png',dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:15:03.763633Z",
     "start_time": "2020-01-14T10:14:49.634008Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.savefig('./all_cells.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T13:21:17.573566Z",
     "start_time": "2020-01-13T13:21:17.535337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Allele information is available for:\n",
    "set( [c for c,i in df['allele1'].sum()[df['allele1'].sum()>0].index] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T13:21:19.788408Z",
     "start_time": "2020-01-13T13:21:19.780603Z"
    }
   },
   "outputs": [],
   "source": [
    "use_allele_info = ['chr18', 'chr4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T13:29:50.973994Z",
     "start_time": "2020-01-13T13:29:50.655275Z"
    }
   },
   "outputs": [],
   "source": [
    "rebin_size = 8\n",
    "\n",
    "new_df_columns = []\n",
    "new_df_column_names = []\n",
    "\n",
    "for contig in use_allele_info:\n",
    "    for allele in ['allele1','allele2']:\n",
    "        for i,bins in enumerate( list( more_itertools.chunked( df[allele][contig].columns, rebin_size) ) ):\n",
    "            if len(bins)!=rebin_size:\n",
    "                continue\n",
    "            new_df_columns.append( df[allele][contig][bins].sum(1) )\n",
    "            new_df_column_names.append( (allele,contig, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T13:29:53.141491Z",
     "start_time": "2020-01-13T13:29:50.978365Z"
    }
   },
   "outputs": [],
   "source": [
    "allelic_df = pd.DataFrame( new_df_columns, index=pd.MultiIndex.from_tuples(new_df_column_names)).T\n",
    "allelic_df = (allelic_df.T / df_wo_alleles.median(1)).T\n",
    "sns.clustermap( allelic_df,vmax=1, col_cluster= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T13:28:27.124547Z",
     "start_time": "2020-01-13T13:28:24.701509Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "allelic_df = pd.DataFrame( new_df_columns, index=pd.MultiIndex.from_tuples(new_df_column_names)).T\n",
    "allelic_df = (allelic_df.T / df['unk'].median(1)).T\n",
    "sns.clustermap( allelic_df, vmax=1, col_cluster= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:46:08.182042Z",
     "start_time": "2020-01-13T12:46:08.130434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove unk column from bins with allelic information\n",
    "df_norm = df_norm.drop([('unk',c) for c in use_allele_info],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T13:03:18.018869Z",
     "start_time": "2020-01-13T13:03:18.008491Z"
    }
   },
   "outputs": [],
   "source": [
    "[ b for b in more_itertools.chunked( df['allele1'][contig].columns, 10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:57:53.055013Z",
     "start_time": "2020-01-13T12:57:53.016904Z"
    }
   },
   "outputs": [],
   "source": [
    "df['allele1'] for contig in use_allele_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:48:59.977950Z",
     "start_time": "2020-01-13T12:48:59.829463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove allele collumns form bins  without allelic information:\n",
    "df_norm = df_norm[ [(allele, contig, b) for allele, contig, b in df_norm.columns if (allele=='unk' or contig in use_allele_info)] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:57:08.926508Z",
     "start_time": "2020-01-13T12:56:58.024809Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:56:38.025694Z",
     "start_time": "2020-01-13T12:56:33.581393Z"
    }
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "sns.clustermap( df_norm[[column for column in df_norm if column[1] in ('chr4', 'chr18')] ], vmax=0.2 , col_cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:49:12.717606Z",
     "start_time": "2020-01-13T12:49:12.680257Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T11:36:22.760783Z",
     "start_time": "2020-01-13T11:36:22.756708Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_regions = df.columns #['chr1', 'chr4', 'chr18', 'chr9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T15:11:24.292068Z",
     "start_time": "2020-01-21T15:09:50.244401Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit( np.clip(0,10, df_norm.fillna(0).T))\n",
    "\n",
    "#ica = FastICA(n_components=10)\n",
    "#ica_X = ica.fit_transform( np.clip(0,10, df_norm.fillna(0)[selected_regions]))\n",
    "\n",
    "tsne = TSNE()\n",
    "tsne_X = tsne.fit_transform( np.clip(0,10, df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:54:35.066624Z",
     "start_time": "2020-01-14T11:54:34.713282Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter( df.sum(1,level=[1,2])['chr4'].sum(1), df.sum(1,level=[1,2])['chr18'].sum(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:54:58.183632Z",
     "start_time": "2020-01-14T11:54:57.645122Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "baf4 = df['allele1']['chr4'].sum(1) / (df['allele1']+df['allele2'])['chr4'].sum(1)\n",
    "baf18 = df['allele1']['chr18'].sum(1) / (df['allele1']+df['allele2'])['chr18'].sum(1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "s = ax.scatter(\n",
    "    df['allele1']['chr18'].sum(1) / (df['allele1']+df['allele2'])['chr18'].sum(1), \n",
    "    df['allele1']['chr4'].sum(1) / (df['allele1']+df['allele2'])['chr4'].sum(1),\n",
    "    c= df.sum(1), norm=matplotlib.colors.LogNorm(),\n",
    "    s=4\n",
    ")\n",
    "ax.set_xlabel('chr18 B-allele frequency')\n",
    "ax.set_ylabel('chr4 B-allele frequency')\n",
    "plt.colorbar(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T11:55:01.966210Z",
     "start_time": "2020-01-14T11:55:01.631228Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "\n",
    "pargs = {'s':8}\n",
    "\n",
    "fig, axes = plt.subplots(1,3, sharex=True, sharey=True)\n",
    "\n",
    "axes[0].scatter( tsne_X[:,0], tsne_X[:,1], c= df.sum(1), norm=matplotlib.colors.LogNorm(),**pargs)\n",
    "\n",
    "\n",
    "axes[1].scatter( tsne_X[:,0], tsne_X[:,1], c= baf4,**pargs)\n",
    "\n",
    "\n",
    "\n",
    "axes[2].scatter( tsne_X[:,0], tsne_X[:,1], c= baf18,  **pargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T12:54:07.578320Z",
     "start_time": "2020-01-13T12:54:07.572655Z"
    }
   },
   "outputs": [],
   "source": [
    "pargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T11:14:25.232079Z",
     "start_time": "2020-01-02T11:14:24.992194Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter( tsne_X[:,0], tsne_X[:,1],# c= np.clip(0, np.percentile(df.sum(1),98), df.sum(1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T11:14:28.097897Z",
     "start_time": "2020-01-02T11:14:27.940087Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter( tsne_X[:,0], tsne_X[:,1], #c= np.clip(0,np.percentile(df[selected_regions].var(1), 90) ,df[selected_regions].var(1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T12:01:43.350578Z",
     "start_time": "2020-01-02T12:01:41.249740Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T12:08:42.648372Z",
     "start_time": "2020-01-02T12:08:42.595096Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm.iloc[block:block+block_size,:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T12:09:03.309307Z",
     "start_time": "2020-01-02T12:09:03.214988Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "block_size = 250\n",
    "for block in range(0, df_norm.shape[0]-block_size, block_size):\n",
    "    df_norm.iloc[block:block+block_size,:].mean().plot.hist(ax=ax,bins=np.linspace(0,1,0.1))\n",
    "    #df_norm.iloc[30:,:]['chr6'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T12:03:05.161133Z",
     "start_time": "2020-01-02T12:02:56.754292Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm = (df.T.fillna(0) / df[ ['chr2','chr3'] ].T.median()).T\n",
    "error = np.abs( np.round(df_norm) - df_norm ).sum(1)\n",
    "#df_norm['ica'] =  tsne_X[:,1] #df_norm.var(1)\n",
    "df_norm['error'] =  error\n",
    "df_norm = df_norm.sort_values('error').drop('error',1)\n",
    "#df_norm = df_norm.sort_values('ica').drop('ica',1)\n",
    "\n",
    "sns.clustermap( df_norm[selected_regions], vmax=3,row_cluster=False, col_cluster= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-02T11:06:14.522015Z",
     "start_time": "2020-01-02T11:06:14.483008Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
